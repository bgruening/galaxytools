<tool id="hyperparameter_finetune" name="Hyperparameter Search for Finetuning model" version="1.0.0" profile="23.0">
    <requirements>
        <requirement type="package" version="2.3.1">pytorch</requirement>
        <requirement type="package" version="4.35.2">transformers</requirement>
        <requirement type="package" version="2.12.0">datasets</requirement>
        <requirement type="package" version="1.26.2">numpy</requirement>
        <requirement type="package" version="2.1.3">pandas</requirement>
        <requirement type="package" version="1.11.4">scipy</requirement>
        <requirement type="package" version="1.3.2">scikit-learn</requirement>
        <requirement type="package" version="3.8.2">matplotlib</requirement>
        <requirement type="package" version="1.81">biopython</requirement>
        <requirement type="package" version="3.6.1">optuna</requirement>
        <requirement type="package" version="2.1.0">smac</requirement>
        <requirement type="package" version="4.66.1">tqdm</requirement>
        <requirement type="package" version="0.24.1">accelerate</requirement>
        <requirement type="package" version="0.4.1">evaluate</requirement>
        <requirement type="package" version="0.1.99">sentencepiece</requirement>
        <requirement type="package" version="5.9.0">plotly</requirement>
        <requirement type="package" version="0.13.2">seaborn</requirement>
    </requirements>
    <command detect_errors="exit_code"><![CDATA[
        python '$__tool_directory__/optuna_tool.py'
        --format '$input_type.format'
        #if $input_type.format == 'fasta':
            #if $input_type.file_mode.mode == 'single':
                #for $i, $input_file in enumerate($input_type.file_mode.input_positive)
                --input_positive_$i '$input_file.input'
                #end for
                #for $i, $input_file in enumerate($input_type.file_mode.input_negative)
                --input_negative_$i '$input_file.input'
                #end for
                --train_percent '$input_type.file_mode.train_percent'
                --test_percent '$input_type.file_mode.test_percent'
                --val_percent '$input_type.file_mode.val_percent'
            #else:
                #for $i, $input_file in enumerate($input_type.file_mode.input_positive_train)
                --input_positive_train_$i '$input_file.input'
                #end for
                #for $i, $input_file in enumerate($input_type.file_mode.input_negative_train)
                --input_negative_train_$i '$input_file.input'
                #end for
                #for $i, $input_file in enumerate($input_type.file_mode.input_positive_test)
                --input_positive_test_$i '$input_file.input'
                #end for
                #for $i, $input_file in enumerate($input_type.file_mode.input_negative_test)
                --input_negative_test_$i '$input_file.input'
                #end for
                --train_percent '$input_type.file_mode.train_percent'
            #end if
        #else:
            #if $input_type.file_number.file_count == 'single':
            --input '$input_type.file_number.input_file'
            --train_percent '$input_type.file_number.train_percent'
            --test_percent '$input_type.file_number.test_percent'
            --val_percent '$input_type.file_number.val_percent'
            #else:
            --train_val '$input_type.file_number.train_val_file'
            --test '$input_type.file_number.test_file'
            --train_percent '$input_type.file_number.train_percent'
            #end if
        #end if
        --model '$model'
        --problem '$problem'
        --hyperparameter_method '$hyperparameter_method.method'
        #if $hyperparameter_method.method == 'manual':
            --lr '$hyperparameter_method.lr'
            --batch '$hyperparameter_method.batch'
            --accum '$hyperparameter_method.accum'
            --dropout '$hyperparameter_method.dropout'
            --weight_decay '$hyperparameter_method.weight_decay'
            --warmup_pct '$hyperparameter_method.warmup_pct'
            --epochs '$hyperparameter_method.epochs'
            --adaptation_method '$hyperparameter_method.adaptation_method.method'
            #if $hyperparameter_method.adaptation_method.method == 'lora':
                --lora_rank '$hyperparameter_method.adaptation_method.lora_rank'
                --lora_init_scale '$hyperparameter_method.adaptation_method.lora_init_scale'
                --lora_scaling_rank '$hyperparameter_method.adaptation_method.lora_scaling_rank'
            #else:
                --dora_rank '$hyperparameter_method.adaptation_method.dora_rank'
                --dora_init_scale '$hyperparameter_method.adaptation_method.dora_init_scale'
            #end if
        #else:
            --optimization_algorithm '$hyperparameter_method.optimization_algorithm'
            --n_trials '$hyperparameter_method.n_trials'
            --lr '$hyperparameter_method.lr'
            --batch '$hyperparameter_method.batch'
            --accum '$hyperparameter_method.accum'
            --dropout '$hyperparameter_method.dropout'
            --weight_decay '$hyperparameter_method.weight_decay'
            --warmup_pct '$hyperparameter_method.warmup_pct'
            --epochs '$hyperparameter_method.epochs'
            --epochs_per_trial '$hyperparameter_method.epochs_per_trial'
            --adaptation_method '$hyperparameter_method.adaptation_method.method'
            #if $hyperparameter_method.adaptation_method.method == 'lora':
                --lora_rank '$hyperparameter_method.adaptation_method.lora_rank'
                --lora_init_scale '$hyperparameter_method.adaptation_method.lora_init_scale'
                --lora_scaling_rank '$hyperparameter_method.adaptation_method.lora_scaling_rank'
            #else:
                --dora_rank '$hyperparameter_method.adaptation_method.dora_rank'
                --dora_init_scale '$hyperparameter_method.adaptation_method.dora_init_scale'
            #end if
        #end if
        --seed '$seed'
    ]]>
    </command>
    <inputs>
        <conditional name="input_type">
            <param name="format" type="select" label="Input file format">
                <option value="fasta">FASTA</option>
                <option value="csv">CSV</option>
            </param>
            <when value="csv">
                <conditional name="file_number">
                    <param name="file_count" type="select" label="Number of input files">
                        <option value="single">Single file (for train/test/val)</option>
                        <option value="double">Two files (one for train/val, one for test)</option>
                    </param>
                    <when value="single">
                        <param name="input_file" type="data" format="csv" label="CSV input file" help="Select your input CSV file for train/test/val"/>
                        <param name="train_percent" type="float" value="0.7" min="0" max="1" label="Training data percentage" help="Proportion of data to use for training (between 0 and 1)"/>
                        <param name="test_percent" type="float" value="0.15" min="0" max="1" label="Testing data percentage" help="Proportion of data to use for testing (between 0 and 1)"/>
                        <param name="val_percent" type="float" value="0.15" min="0" max="1" label="Validation data percentage" help="Proportion of data to use for validation (between 0 and 1)"/>
                        <!-- <validator type="expression" message="Percentages must sum to 1">float($train_percent) + float($test_percent) + float($val_percent) == 1</validator> -->
                    </when>
                    <when value="double">
                        <param name="train_val_file" type="data" format="csv" label="CSV input file for train/val" help="Select your input CSV file for train/val"/>
                        <param name="test_file" type="data" format="csv" label="CSV input file for test" help="Select your input CSV file for test"/>
                        <param name="train_percent" type="float" value="0.8" min="0" max="1" label="Training data percentage" help="Proportion of train/val data to use for training (between 0 and 1)"/>
                        <!-- <validator type="expression" message="Training percentage must be less than 1">float($train_percent) < 1</validator> -->
                    </when>
                </conditional>
            </when>
            <when value="fasta">
                <conditional name="file_mode">
                    <param name="mode" type="select" label="File input mode">
                        <option value="single">Single file (train/val/test)</option>
                        <option value="double">Two files (train/val and test)</option>
                    </param>
                    <when value="single">
                        <repeat name="input_positive" title="Positive FASTA files">
                            <param name="input" type="data" format="fasta" label="Positive FASTA file" help="Input FASTA file to be labeled as positive"/>
                        </repeat>
                        <repeat name="input_negative" title="Negative FASTA files">
                            <param name="input" type="data" format="fasta" label="Negative FASTA file" help="Input FASTA file to be labeled as negative"/>
                        </repeat>
                        <param name="train_percent" type="float" value="0.7" min="0" max="1" label="Training data percentage" help="Proportion of data to use for training (between 0 and 1)"/>
                        <param name="test_percent" type="float" value="0.15" min="0" max="1" label="Testing data percentage" help="Proportion of data to use for testing (between 0 and 1)"/>
                        <param name="val_percent" type="float" value="0.15" min="0" max="1" label="Validation data percentage" help="Proportion of data to use for validation (between 0 and 1)"/>
                    </when>
                    <when value="double">
                        <repeat name="input_positive_train" title="Positive FASTA files (Train/Val)">
                            <param name="input" type="data" format="fasta" label="Positive FASTA file (Train/Val)" help="Input FASTA file to be labeled as positive for train/val"/>
                        </repeat>
                        <repeat name="input_negative_train" title="Negative FASTA files (Train/Val)">
                            <param name="input" type="data" format="fasta" label="Negative FASTA file (Train/Val)" help="Input FASTA file to be labeled as negative for train/val"/>
                        </repeat>
                        <repeat name="input_positive_test" title="Positive FASTA files (Test)">
                            <param name="input" type="data" format="fasta" label="Positive FASTA file (Test)" help="Input FASTA file to be labeled as positive for test"/>
                        </repeat>
                        <repeat name="input_negative_test" title="Negative FASTA files (Test)">
                            <param name="input" type="data" format="fasta" label="Negative FASTA file (Test)" help="Input FASTA file to be labeled as negative for test"/>
                        </repeat>
                        <param name="train_percent" type="float" value="0.8" min="0" max="1" label="Training data percentage" help="Proportion of train/val data to use for training (between 0 and 1)"/>
                    </when>
                </conditional>
            </when>
        </conditional>
        <param name="problem" type="select" label="Problem Selection">
            <option value="dephos">Dephosphorylation</option>
            <option value="other">Other</option>
        </param>
        <param name="model" type="select" label="Model Selection">
            <option value="pt5-xl50">ProtT5-XL-UniRef50</option>
            <option value="esm">ESM-2</option>
            <option value="pt5-bfd">ProtT5-XL-BFD</option>
        </param>
        <conditional name="hyperparameter_method">
            <param name="method" type="select" label="Hyperparameter Selection Method">
                <option value="manual">Manual Selection</option>
                <option value="auto">Automated Hyperparameter Search</option>
            </param>
            <when value="manual">
                <param name="lr" type="float" value="3e-5" label="Learning Rate" help="Learning rate for the optimizer"/>
                <param name="batch" type="select" label="Batch Size" help="Number of samples processed together">
                    <option value="1">1</option>
                    <option value="2">2</option>
                    <option value="4">4</option>
                    <option value="8" selected="true">8</option>
                    <option value="16">16</option>
                </param>
                <param name="accum" type="select" label="Gradient Accumulation Steps" help="Number of steps to accumulate gradients before updating">
                    <option value="1">1</option>
                    <option value="2" selected="true">2</option>
                    <option value="4">4</option>
                    <option value="8">8</option>
                </param>
                <param name="dropout" type="float" value="0.1" min="0" max="1" label="Dropout Rate" help="Fraction of units to drop for regularization"/>
                <param name="weight_decay" type="float" value="0.01" min="0" max="1" label="Weight Decay" help="L2 regularization term"/>
                <param name="warmup_pct" type="float" value="0.1" min="0" max="1" label="Warmup Percentage" help="Fraction of total steps for learning rate warmup"/>
                <param name="epochs" type="integer" value="20" min="1" label="Number of Epochs" help="Number of training epochs"/>
                <conditional name="adaptation_method">
                    <param name="method" type="select" label="Adaptation Method">
                        <option value="lora">LoRA</option>
                        <option value="dora">DoRA</option>
                    </param>
                    <when value="lora">
                        <param name="lora_rank" type="integer" value="4" min="1" label="LoRA Rank" help="Rank for Low-Rank Adaptation"/>
                        <param name="lora_init_scale" type="float" value="0.01" min="0" max="1" label="LoRA Init Scale" help="Initial scale for LoRA weights"/>
                        <param name="lora_scaling_rank" type="integer" value="4" min="1" label="LoRA Scaling Rank" help="Scaling rank for LoRA. This will contribute to the affect of LoRA with percentage lora_scaling_rank/lora_rank"/>
                    </when>
                    <when value="dora">
                        <param name="dora_rank" type="integer" value="4" min="1" label="DoRA Rank" help="Rank for Dense-to-Rank Adaptation"/>
                        <param name="dora_init_scale" type="float" value="0.01" min="0" max="1" label="DoRA Init Scale" help="Initial scale for DoRA weights"/>
                    </when>
                </conditional>
            </when>
            <when value="auto">
                <param name="optimization_algorithm" type="select" label="Optimization Algorithm">
                    <option value="optuna">Optuna</option>
                    <!-- <option value="smac3">SMAC3</option> -->
                </param>
                <param name="n_trials" type="integer" value="10" min="1" label="Number of trials" help="Number of parameter settings that are sampled"/>
                <param name="lr" type="text" value="(1e-5,1e-2)" label="Learning Rate Range" help="(min,max) values for learning rate (log scale)"/>
                <param name="batch" type="text" value="[1,2,4,8]" label="Batch Size Options" help="[option1,option2,...] for batch size"/>
                <param name="accum" type="text" value="[2,4,8]" label="Gradient Accumulation Options" help="[option1,option2,...] for gradient accumulation steps"/>
                <param name="dropout" type="text" value="(0.1,0.9)" label="Dropout Rate Range" help="(min,max) values for dropout rate"/>
                <param name="weight_decay" type="text" value="(1e-5,1e-3)" label="Weight Decay Range" help="(min,max) values for weight decay (log scale)"/>
                <param name="warmup_pct" type="text" value="(0.01,0.3)" label="Warmup Percentage Range" help="(min,max) values for warmup percentage"/>
                <param name="epochs_per_trial" type="integer" value="5" min="1" label="Number of Epochs per Trial" help="Number of training epochs for each trial"/>
                <param name="epochs" type="integer" value="20" min="1" label="Number of Epochs for Final Run" help="Number of epochs for the best trial"/>
                <conditional name="adaptation_method">
                    <param name="method" type="select" label="Adaptation Method">
                        <option value="lora">LoRA</option>
                        <option value="dora">DoRA</option>
                    </param>
                    <when value="lora">
                        <param name="lora_rank" type="text" value="(4,32,4)" label="LoRA Rank Range" help="(min,max,step) values for LoRA rank"/>
                        <param name="lora_init_scale" type="text" value="(1e-4,1e-1)" label="LoRA Init Scale Range" help="(min,max) values for LoRA init scale (log scale)"/>
                        <param name="lora_scaling_rank" type="text" value="(4,32,4)" label="LoRA Scaling Rank Range" help="(min,max,step) values for LoRA scaling rank"/>
                    </when>
                    <when value="dora">
                        <param name="dora_rank" type="text" value="(4,32,4)" label="DoRA Rank Range" help="(min,max,step) values for DoRA rank"/>
                        <param name="dora_init_scale" type="text" value="(1e-4,1e-1)" label="DoRA Init Scale Range" help="(min,max) values for DoRA init scale (log scale)"/>
                    </when>
                </conditional>
            </when>
        </conditional>
        <param name="seed" type="integer" value="42" min="0" label="Random Seed" help="Set a seed for reproducibility (default: 42)"/>
    </inputs>
    <outputs>
        <data name="training_history" format="pdf" from_work_dir="Training_History_with_metric.pdf" label="Training History Plot" />
        <data name="metrics_table" format="csv" from_work_dir="metrics_table.csv" label="Metrics Table" />
        <data name="Confusion_Matrix" format="png" from_work_dir="confusion_matrix.png" label="Confusion Matrix" />
        <data name="Model_Output" format="pth" from_work_dir="model_output/finetuned_model.pth" label="Finetune Model"></data>
        
        <!-- Optuna outputs -->
        <data name="optuna_trial" format="sqlite3" from_work_dir="optuna_results.sqlite3" label="Optuna Results">
            <filter>hyperparameter_method['method'] == "auto" and hyperparameter_method['optimization_algorithm'] == "optuna"</filter>
        </data>
        <data name="optuna_incumbents" format="txt" from_work_dir="optuna_incumbents.txt" label="Optuna Incumbent List">
            <filter>hyperparameter_method['method'] == "auto" and hyperparameter_method['optimization_algorithm'] == "optuna"</filter>
        </data>
        
        <!-- SMAC outputs (commented out as it's not in your current input options) -->
        <!--
        <data name="smac_runhistory" format="json" from_work_dir="runhistory.json" label="SMAC Run History">
            <filter>hyperparameter_method['method'] == "auto" and hyperparameter_method['optimization_algorithm'] == "smac3"</filter>
        </data>
        <data name="smac_incumbents" format="txt" from_work_dir="smac_incumbents.txt" label="SMAC Incumbent List">
            <filter>hyperparameter_method['method'] == "auto" and hyperparameter_method['optimization_algorithm'] == "smac3"</filter>
        </data>
        -->
    </outputs>
    <tests>
        <test expect_num_outputs="4">
            <param name="input_type|format" value="fasta"/>
            <param name="input_type|file_mode|mode" value="double"/>
            <param name="input_type|file_mode|input_positive_train_0|input" value="train_Pos_Y.fasta"/>
            <param name="input_type|file_mode|input_negative_train_0|input" value="train_Neg_Y.fasta"/>
            <param name="input_type|file_mode|input_positive_test_0|input" value="test_Pos_Y.fasta"/>
            <param name="input_type|file_mode|input_negative_test_0|input" value="test_Neg_Y.fasta"/>
            <param name="input_type|file_mode|train_percent" value="0.8"/>
            <param name="model" value="pt5-xl50"/>
            <param name="problem" value="dephos"/>
            <param name="hyperparameter_method|method" value="manual"/>
            <param name="hyperparameter_method|lr" value="3e-05"/>
            <param name="hyperparameter_method|batch" value="8"/>
            <param name="hyperparameter_method|accum" value="2"/>
            <param name="hyperparameter_method|dropout" value="0.1"/>
            <param name="hyperparameter_method|weight_decay" value="0.01"/>
            <param name="hyperparameter_method|warmup_pct" value="0.1"/>
            <param name="hyperparameter_method|epochs" value="20"/>
            <param name="hyperparameter_method|adaptation_method|method" value="lora"/>
            <param name="hyperparameter_method|adaptation_method|lora_rank" value="4"/>
            <param name="hyperparameter_method|adaptation_method|lora_init_scale" value="0.01"/>
            <param name="hyperparameter_method|adaptation_method|lora_scaling_rank" value="4"/>
            <param name="seed" value="42"/>
    
            <output name="training_history" file="test1/training_history.pdf" compare="sim_size"/>
            <output name="metrics_table" file="test1/metrics_table.csv" compare="re_match" lines_diff="0"/>
            <output name="Confusion_Matrix" file="test1/confusion_matrix.png" compare="sim_size"/>
            <output name="Model_Output" file="test1/finetuned_model.pth" compare="sim_size"/>
        </test>
        
        <test expect_num_outputs="6">
            <param name="input_type|format" value="fasta"/>
            <param name="input_type|file_mode|mode" value="double"/>
            <param name="input_type|file_mode|input_positive_train_0|input" value="train_Pos_Y.fasta"/>
            <param name="input_type|file_mode|input_negative_train_0|input" value="train_Neg_Y.fasta"/>
            <param name="input_type|file_mode|input_positive_test_0|input" value="test_Pos_Y.fasta"/>
            <param name="input_type|file_mode|input_negative_test_0|input" value="test_Neg_Y.fasta"/>
            <param name="input_type|file_mode|train_percent" value="0.8"/>
            <param name="model" value="esm"/>
            <param name="problem" value="dephos"/>
            <param name="hyperparameter_method|method" value="auto"/>
            <param name="hyperparameter_method|optimization_algorithm" value="optuna"/>
            <param name="hyperparameter_method|n_trials" value="10"/>
            <param name="hyperparameter_method|lr" value="(1e-5,1e-2)"/>
            <param name="hyperparameter_method|batch" value="[1,2,4,8]"/>
            <param name="hyperparameter_method|accum" value="[2,4,8]"/>
            <param name="hyperparameter_method|dropout" value="(0.1,0.9)"/>
            <param name="hyperparameter_method|weight_decay" value="(1e-5,1e-3)"/>
            <param name="hyperparameter_method|warmup_pct" value="(0.01,0.3)"/>
            <param name="hyperparameter_method|epochs" value="20"/>
            <param name="hyperparameter_method|epochs_per_trial" value="5"/>
            <param name="hyperparameter_method|adaptation_method|method" value="dora"/>
            <param name="hyperparameter_method|adaptation_method|dora_rank" value="(4,32,4)"/>
            <param name="hyperparameter_method|adaptation_method|dora_init_scale" value="(1e-4,1e-1)"/>
            <param name="seed" value="42"/>
    
            <output name="training_history" file="test2/training_history_esm_dora.pdf" compare="sim_size"/>
            <output name="metrics_table" file="test2/metrics_table_esm_dora.csv" compare="re_match" lines_diff="0"/>
            <output name="Confusion_Matrix" file="test2/confusion_matrix_esm_dora.png" compare="sim_size"/>
            <output name="Model_Output" file="test2/finetuned_model_esm_dora.pth" compare="sim_size"/>
            <output name="optuna_trial" file="test2/optuna_results_esm_dora.sqlite3" compare="sim_size"/>
            <output name="optuna_incumbents" file="test2/optuna_incumbents_esm_dora.txt" compare="re_match" lines_diff="0"/>
        </test>
    </tests>
    <help><![CDATA[
    .. class:: infomark
    
    **What it does**
    
    This tool performs protein sequence classification using a fine-tuned model with LoRA (Low-Rank Adaptation) or DoRA (Dense-to-Rank Adaptation). It supports manual hyperparameter selection or automated hyperparameter search using either Optuna or SMAC3.
    
    **Inputs**
    
    1. Input Files:
        - For single file mode: One merged file containing both positive and negative examples.
        - For two file mode: Two merged files, one for train/validation and one for testing.
        - For the dephosphorylation problem, ensure all sequences have the same length, with the residue of interest (S, T, or Y) positioned in the middle of the sequence.
        - For the CSV format, you must have these columns: "sequence", "label"
    
    2. Problem selection:
        - Choose between Dephosphorylation and Other. For the dephosphorylation problem, the attention will focus on the middle residue of the sequence.
    
    3. Model Selection:
        - Choose between ProtT5-XL-UniRef50, ESM, or ProtT5-XL-BFD models.
    
    4. Hyperparameter Selection Method:
        - Manual: Set specific values for all hyperparameters.
        - Automated: Use Optuna or SMAC3 for hyperparameter optimization.
    
    5. Adaptation Method:
        - LoRA: Low-Rank Adaptation
        - DoRA: Dense-to-Rank Adaptation
    
    6. Training Parameters:
        - Various hyperparameters including learning rate, batch size, etc.
        - Ranges or options for these parameters when using automated search.
    
    **Outputs**
    
    1. Trained Model: The best performing model saved during training.
    2. Performance Metrics: Accuracy, loss, and other relevant metrics.
    3. Hyperparameter Search Results: If using automated search, a summary of the optimization process.
    
    **How to use**
    
    1. Select your input file(s) and set the data split percentages.
    2. Choose the model you want to use.
    3. Select the hyperparameter selection method (manual or automated).
    4. If manual, input your desired hyperparameter values.
    5. If automated, choose between Optuna and SMAC3, and define the ranges for each hyperparameter.
    6. Select the adaptation method (LoRA or DoRA) and set its parameters.
    7. Run the tool and review the output metrics and model performance.
    
    **Note**
    
    - Ensure your input files are properly formatted with labels.
    - The tool uses GPU acceleration if available, which can significantly reduce processing time.
    - For large datasets or extensive hyperparameter searches, the tool may take a considerable amount of time to run.
    - Optuna and SMAC3 are both powerful hyperparameter optimization frameworks. Optuna uses various sampling methods and pruning techniques, while SMAC3 uses Bayesian optimization with random forests.
    ]]></help>
    <citations>
        <citation type="bibtex">
            @article{elnaggar2021prottrans,
                title={Prottrans: Toward understanding the language of life through self-supervised learning},
                author={Elnaggar, Ahmed and Heinzinger, Michael and Dallago, Christian and Rehawi, Ghalia and Wang, Yu and Jones, Llion and Gibbs, Tom and Feher, Tamas and Angerer, Christoph and Steinegger, Martin and others},
                journal={IEEE transactions on pattern analysis and machine intelligence},
                volume={44},
                number={10},
                pages={7112--7127},
                year={2021},
                publisher={IEEE}
            }
        </citation>
        <citation type="bibtex">
            @article{schmirler2024fine,
                title={Fine-tuning protein language models boosts predictions across diverse tasks},
                author={Schmirler, Robert and Heinzinger, Michael and Rost, Burkhard},
                journal={Nature Communications},
                volume={15},
                number={1},
                pages={7407},
                year={2024},
                publisher={Nature Publishing Group UK London}
            }
        </citation>
    </citations>
</tool>