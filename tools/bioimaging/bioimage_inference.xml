<tool id="bioimage_inference" name="Process image using a BioImage.IO model" version="@TOOL_VERSION@+galaxy@VERSION_SUFFIX@" profile="23.0">
    <description>with PyTorch</description>
    <macros>
        <token name="@TOOL_VERSION@">2.4.1</token>
        <token name="@VERSION_SUFFIX@">1</token>
    </macros>
    <creator>
        <organization name="European Galaxy Team" url="https://galaxyproject.org/eu/" />
        <person givenName="Anup" familyName="Kumar" email="kumara@informatik.uni-freiburg.de" />
        <person givenName="Beatriz" familyName="Serrano-Solano" email="beatriz.serrano.solano@eurobioimaging.eu" />
        <person givenName="Leonid" familyName="Kostrykin" email="leonid.kostrykin@bioquant.uni-heidelberg.de" />
    </creator>
    <edam_operations>
        <edam_operation>operation_3443</edam_operation>
    </edam_operations>
    <xrefs>
        <xref type="bio.tools">pytorch</xref>
        <xref type="biii">pytorch</xref>
    </xrefs>
    <requirements>
        <requirement type="package" version="3.9.12">python</requirement>
        <requirement type="package" version="@TOOL_VERSION@">pytorch</requirement>
        <requirement type="package" version="0.19.1">torchvision</requirement>
        <requirement type="package" version="2.35.1">imageio</requirement>
    </requirements>
    <version_command>echo "@VERSION@"</version_command>
    <command detect_errors="aggressive">
    <![CDATA[
        python '$__tool_directory__/main.py'
            --imaging_model '$input_imaging_model'
            --image_file '$input_image_file'
            --image_size '$input_image_input_size'
            --image_axes '$input_image_input_axes'
    ]]>
    </command>
    <inputs>
        <param name="input_imaging_model" type="data" format="zip" label="BioImage.IO model" help="Please upload a BioImage.IO model."/>
        <param name="input_image_file" type="data" format="tiff,png" label="Input image" help="Please provide an input image for the analysis."/>
        <param name="input_image_input_size" type="text" optional="false" label="Size of the input image" help="Provide the size of the input image. See the chosen model's RDF file to find the correct input size. For example: for the BioImage.IO model MitochondriaEMSegmentationBoundaryModel, the input size is 256 x 256 x 32 x 1. Enter the size as 256,256,32,1."/>
        <param name="input_image_input_axes" type="select" label="Axes of the input image" optional="false" help="Provide the input axes of the input image. See the chosen model's RDF file to find the correct axes. For example: for the BioImage.IO model MitochondriaEMSegmentationBoundaryModel, the input axes is 'bczyx'">
            <option value="bczyx">bczyx</option>
            <option value="bcyx">bcyx</option>
            <option value="byxc">byxc</option>
        </param>
    </inputs>
    <outputs>
        <data format="tif" name="output_predicted_image" from_work_dir="output_predicted_image.tif" label="Predicted image"></data>
        <data format="npy" name="output_predicted_image_matrix" from_work_dir="output_predicted_image_matrix.npy" label="Predicted image tensor"></data>
    </outputs>
    <tests>
        <test>
            <param name="input_imaging_model" value="input_imaging_model.zip" location="https://zenodo.org/api/records/6647674/files/weights-torchscript.pt/content"/>
            <param name="input_image_file" value="input_image_file.tif" location="https://zenodo.org/api/records/6647674/files/sample_input_0.tif/content"/>
            <param name="input_image_input_size" value="256,256,1,1"/>
            <param name="input_image_input_axes" value="bcyx"/>
            <output name="output_predicted_image" ftype="tif">
                <assert_contents>
                    <has_size size="524846" delta="110" />
                </assert_contents>
            </output>
            <output name="output_predicted_image_matrix" ftype="npy">
                <assert_contents>
                    <has_size size="524416" delta="110" />
                </assert_contents>
            </output>
        </test>
        <test>
            <param name="input_imaging_model" value="input_imaging_model.zip" location="https://zenodo.org/api/records/6647674/files/weights-torchscript.pt/content"/>
            <param name="input_image_file" value="input_nucleisegboundarymodel.png"/>
            <param name="input_image_input_size" value="256,256,1,1"/>
            <param name="input_image_input_axes" value="bcyx"/>
            <output name="output_predicted_image" ftype="tif">
                <assert_contents>
                    <has_size size="524846" delta="110" />
                </assert_contents>
            </output>
            <output name="output_predicted_image_matrix" ftype="npy">
                <assert_contents>
                    <has_size size="524416" delta="110" />
                </assert_contents>
            </output>
        </test>
        <test>
            <param name="input_imaging_model" value="input_imaging_model.zip" location="https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/emotional-cricket/1.1/files/torchscript_tracing.pt"/>
            <param name="input_image_file" value="input_image_file.tif" location="https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/emotional-cricket/1.1/files/sample_input_0.tif"/>
            <param name="input_image_input_size" value="128,128,100,1"/>
            <param name="input_image_input_axes" value="bczyx"/>
            <output name="output_predicted_image" ftype="tif">
                <assert_contents>
                    <has_size size="6572778" delta="100" />
                </assert_contents>
            </output>
            <output name="output_predicted_image_matrix" ftype="npy">
                <assert_contents>
                    <has_size size="6572778" delta="100" />
                </assert_contents>
            </output>
        </test>
        <test>
            <param name="input_imaging_model" value="input_imaging_model.zip" location="https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/emotional-cricket/1.1/files/torchscript_tracing.pt"/>
            <param name="input_image_file" value="input_3d-unet-arabidopsis-apical-stem-cells.png" location="https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/emotional-cricket/1.1/files/raw.png"/>
            <param name="input_image_input_size" value="128,128,100,1"/>
            <param name="input_image_input_axes" value="bczyx"/>
            <output name="output_predicted_image" ftype="tif">
                <assert_contents>
                    <has_size size="6572778" delta="100" />
                </assert_contents>
            </output>
            <output name="output_predicted_image_matrix" ftype="npy">
                <assert_contents>
                    <has_size size="6572778" delta="100" />
                </assert_contents>
            </output>
        </test>
        <test>
            <param name="input_imaging_model" value="input_imaging_model.zip" location="https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/organized-badger/1/files/weights-torchscript.pt"/>
            <param name="input_image_file" value="input_platynereisemnucleisegmentationboundarymodel.tif" location="https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/organized-badger/1/files/sample_input_0.tif"/>
            <param name="input_image_input_size" value="256,256,32,1"/>
            <param name="input_image_input_axes" value="bczyx"/>
            <output name="output_predicted_image" ftype="tif">
                <assert_contents>
                    <has_size size="16789714" delta="100" />
                </assert_contents>
            </output>
            <output name="output_predicted_image_matrix" ftype="npy">
                <assert_contents>
                    <has_size size="16777344" delta="100" />
                </assert_contents>
            </output>
        </test>
        <test>
            <param name="input_imaging_model" value="input_imaging_model.zip" location="https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/thoughtful-turtle/1/files/torchscript_tracing.pt"/>
            <param name="input_image_file" value="input_3d-unet-lateral-root-primordia-cells.tif" location="https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/thoughtful-turtle/1/files/sample_input_0.tif"/>
            <param name="input_image_input_size" value="128,128,100,1"/>
            <param name="input_image_input_axes" value="bczyx"/>
            <output name="output_predicted_image" ftype="tif">
                <assert_contents>
                    <has_size size="6572778" delta="100" />
                </assert_contents>
            </output>
            <output name="output_predicted_image_matrix" ftype="npy">
                <assert_contents>
                    <has_size size="6553728" delta="100" />
                </assert_contents>
            </output>
        </test>
    </tests>
    <help>
        <![CDATA[
            **What it does**

            The tool takes a BioImage.IO model and an image (as TIF or PNG) to be analyzed. The analysis is performed by the model. The model is used to obtain a prediction of the result of the analysis, and the predicted image becomes available as a TIF file in the Galaxy history.

            **Input files**
                - BioImage.IO model: Add one of the model from Galaxy file uploader by choosing a "remote" file at "ML Models/bioimaging-models"
                - Image to be analyzed: Provide an image as TIF/PNG file
                - Provide the necessary input size for the model. This information can be found in the RDF file of each model (RDF file > config > test_information > inputs > size)
                - Provide axes of input image. This information can also be found in the RDF file of each model (RDF file > inputs > axes). An example value of axes is 'bczyx' for 3D U-Net Arabidopsis Lateral Root Primordia model

            **Output files**
                - Predicted image: Predicted image using the BioImage.IO model
                - Predicted image matrix: Predicted image matrix in original dimensions
        ]]>
    </help>
    <citations>
        <citation type="doi">10.1145/3620665.3640366</citation>
        <citation type="doi">10.1101/2022.06.07.495102</citation>
    </citations>
</tool>
