#This is a sample file distributed with Galaxy that is used to define litellm
#models, using 6 columns tab separated
#(longer whitespace are TAB characters):
#
#<value>	<model_id>	<name>	<domain>	<provider>	<free_tag>
#
#value: Unique identifier for the dropdown selection
#model_id: The actual model identifier to send to the LiteLLM API
#name: Display name shown to users in the Galaxy interface
#domain: Model type - text, image, or multimodal
#provider: Server identifier matching a key in the servers section of your YAML config
#free_tag: Optional tag that can be freely used by admins to specify additional filter options
#
#Examples:
#
#
#gpt-oss-20b	gpt-oss-20b-llmlb	GPT-OSS Local (20B)	text	uni-freiburg	openai
#gpt-oss-120b	gpt-oss-120b-llmlb	GPT-OSS Pro (120B)	text	uni-freiburg	openai
#deepseek-qwen-8b	deepseek-r1-0528-qwen3-8b-llmlb	DeepSeek Qwen Chat (8B)	text	uni-freiburg	deepseek
#gemma-3-12b-freiburg	gemma-3-12b-llmlb	Gemma 3 (12B) - Freiburg	multimodal	uni-freiburg	google
#gemma-3-12b-custom	gemma-3-12b-llmlb	Gemma 3 (12B) - Custom	multimodal	custom-server	google
#llama-3.1-8b	llama-3.1-8b-fp8-llmlb	LLaMA 3.1 (8B)	text	uni-freiburg	meta
#qwen2.5-vl-7b	qwen2.5-vl-7b-llmlb	Qwen 2.5 VL (7B)	multimodal	uni-freiburg	alibaba
#
#Note: The same model (same model_id) can be provided by different servers by using
#different value identifiers and provider fields. See gemma-3-12b examples above.