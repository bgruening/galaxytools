<tool id="doclayoutyolo" name="DocLayout-YOLO" version="@TOOL_VERSION@+galaxy@VERSION_SUFFIX@" profile="@PROFILE@">
    <description>Enhancing document layout analysis</description>
    <macros>
        <token name="@TOOL_VERSION@">0.0.4.1</token>
        <token name="@VERSION_SUFFIX@">0</token>
        <token name="@PROFILE@">24.2</token>
    </macros>
    <creator>
        <organization name="European Galaxy Team" url="https://galaxyproject.org/eu/"/>
        <person givenName="Anup" familyName="Kumar" email="kumara@informatik.uni-freiburg.de"/>
    </creator>
    <requirements>
        <container type="docker">quay.io/galaxy/doclayout-yolo:@TOOL_VERSION@</container>
    </requirements>
    <required_files>
        <include path="segment_text_yolo.py"/>
    </required_files>
    <command detect_errors="aggressive"><![CDATA[
    python '$__tool_directory__/segment_text_yolo.py'
            --yolo_model '$input_yolo_model'
            --input_image '$input_image'
            --input_image_ext '$input_image.ext'
            --input_confidence '$input_confidence'
            --input_image_size '$input_image_size'
            --output_image '$output_image'
            --output_geojson '$output_segmentation_coordinates'
]]>
    </command>
    <inputs>
        <param name="input_yolo_model" type="data" format="zip" label="Yolo model" help="Please upload a Yolo model."/>
        <param name="input_image" type="data" format="tiff,jpg,png" label="Input image" help="Please provide an input image for the analysis."/>
        <param name="input_confidence" type="float" label="Confidence" value="0.5" min="0.0" max="1.0" help="Set confidence threshold between 0.0 and 1.0 for drawing bounding boxes. Higher values indicate higher probablity of segmentation."/>
        <param name="input_image_size" type="integer" label="Image size" value="1024" min="1" max="1500" help="Set input image size for image resize by Doclayout Yolo model. Larger values may provide better accuracy in segmentation but could be slower. Lower values might be faster with lower accuracy."/>
    </inputs>
    <outputs>
        <data format_source="input_image" name="output_image" label="Segmented image"></data>
        <data format="geojson" name="output_segmentation_coordinates" label="Segmented coordinates"></data>
    </outputs>
    <tests>
        <test>
            <param name="input_yolo_model" value="input_yolo_model.zip" location="https://huggingface.co/juliozhao/DocLayout-YOLO-DocLayNet-Docsynth300K_pretrained/resolve/main/doclayout_yolo_doclaynet_imgsz1120_docsynth_pretrain.pt?download=true"/>
            <param name="input_image" value="input_image_png.png"/>
            <param name="input_confidence" value="0.5"/>
            <param name="input_image_size" value="1024"/>
            <output name="output_image" ftype="png">
                <assert_contents>
                    <has_size size="920950" delta="100" />
                </assert_contents>
            </output>
            <output name="output_segmentation_coordinates" ftype="geojson">
                <assert_contents>
                    <has_text text="Polygon" />
                    <has_text text="Feature" />
                    <has_text text="coordinates" />
                </assert_contents>
            </output>
        </test>
        <test>
            <param name="input_yolo_model" value="input_yolo_model.zip" location="https://huggingface.co/juliozhao/DocLayout-YOLO-DocLayNet-Docsynth300K_pretrained/resolve/main/doclayout_yolo_doclaynet_imgsz1120_docsynth_pretrain.pt?download=true"/>
            <param name="input_image" value="input_image_jpg.jpg" location="https://zenodo.org/records/15649779/files/input_image_jpg.jpg?download=1"/>
            <param name="input_confidence" value="0.5"/>
            <param name="input_image_size" value="1024"/>
            <output name="output_image" ftype="jpg">
                <assert_contents>
                    <has_size size="2753175" delta="100" />
                </assert_contents>
            </output>
            <output name="output_segmentation_coordinates" ftype="geojson">
                <assert_contents>
                    <has_text text="Polygon" />
                    <has_text text="Feature" />
                    <has_text text="coordinates" />
                </assert_contents>
            </output>
        </test>
        <test>
            <param name="input_yolo_model" value="input_yolo_model.zip" location="https://huggingface.co/juliozhao/DocLayout-YOLO-DocLayNet-Docsynth300K_pretrained/resolve/main/doclayout_yolo_doclaynet_imgsz1120_docsynth_pretrain.pt?download=true"/>
            <param name="input_image" value="input_image_tiff.tif"/>
            <param name="input_confidence" value="0.5"/>
            <param name="input_image_size" value="1024"/>
            <output name="output_image" ftype="tiff">
                <assert_contents>
                    <has_size size="510756" delta="100" />
                </assert_contents>
            </output>
            <output name="output_segmentation_coordinates" ftype="geojson">
                <assert_contents>
                    <has_text text="Polygon" />
                    <has_text text="Feature" />
                    <has_text text="coordinates" />
                </assert_contents>
            </output>
        </test>
    </tests>
    <help>
        <![CDATA[
**What it does**

The tool takes a Yolo model trained for annotating bounding boxes around text. It takes a pretrained Yolo model and predicts bounding boxes in the input image where any text is found.
It is based on document layout analysis: https://github.com/opendatalab/DocLayout-YOLO. The Yolo model can be downloaded from: https://huggingface.co/juliozhao/DocLayout-YOLO-DocLayNet-Docsynth300K_pretrained/tree/main
 

**Input files**
  - Yolo model (as `.pt` file)
  - Input image containing text
  - Confidence score to be used for drawing bounding boxes
  - Image size to be resized to by Yolo model

**Output files**
  - Segmented image
  - Coordinates of bounding boxes as Geojson file

        ]]>
    </help>
    <citations>
        <citation type="bibtex">
            @ARTICLE{zhao2024doclayoutyoloenhancingdocumentlayout,
                Author = {Zhao, Zhiyuan and et al.},
                title = {{DocLayout-YOLO: Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception}},
                url = {https://github.com/opendatalab/DocLayout-YOLO}
            }
        </citation>
    </citations>
</tool>
