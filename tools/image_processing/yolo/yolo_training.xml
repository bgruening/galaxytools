<tool id="yolo_training" name="Perform YOLO training" version="@TOOL_VERSION@+galaxy5" profile="24.2">
    <description>with ultralytics</description>
    <macros>
        <import>macros.xml</import>
    </macros>
    <expand macro="creator" />
    <expand macro="edam" />
    <expand macro="requirements" />
    <command detect_errors="aggressive">
    <![CDATA[
      export YOLO_CONFIG_DIR='\$HOME/.config/ultralytics' &&

      mkdir -p ./input_images ./input_yolo ./training ./runs ./models output_files && 

      #for $filename in $input_images:
        #if $filename.element_identifier.endswith($filename.ext)
            ln -s '$filename' './input_images/${filename.element_identifier}' &&
        #else
            ln -s '$filename' './input_images/${filename.element_identifier}.${filename.ext}' &&
        #end if
      #end for
	
      #for $yolo in $input_yolo:
        #if $yolo.element_identifier.endswith($yolo.ext)
            ln -s '$yolo' './input_yolo/${yolo.element_identifier}' &&
        #else:
            ln -s '$yolo' './input_yolo/${yolo.element_identifier}.${yolo.ext}' &&
        #end if
      #end for
      
      python '$__tool_directory__/preprocessing.py' 
        -i './input_images' 
        -y './input_yolo' 
        -o ./training 
        -c '$class_names'
        -p '$num_train' &&

      #if $model_choice.pretrained == 'personal'
        cp '$model_choice.model_input' ./models/yolo_model.pt &&
      #else
        wget '$model_choice.pretrained' -O ./models/yolo_model.pt &&
      #end if

      python '$__tool_directory__/yolov8.py' 
		    --train --yaml_path='./training/yolo.yml' 
		    --model_path='./models' 
     		--model_name='yolo_model'
		    --run_dir='./runs' 
		    --image_size='$training_params.image_size'
		    --epochs='$training_params.epochs'
		    --scale='$training_params.scale'
		    --degree='$training_params.degree'
		    --hsv_v='$training_params.hsv_v'
		    --hsv_s='$training_params.hsv_s'
		    --hsv_h='$training_params.hsv_h'
		    --init_lr='$training_params.init_lr'
		    --weight_decay='$training_params.weight_decay'
		    --confidence='$training_params.confidence'
		    --iou='$training_params.iou'
		    --max_det='$training_params.max_det'  
      &&

      cp ./runs/train*/*/best.pt output_files/best.pt &&
      cp ./runs/train*/*/last.pt output_files/last.pt &&
      cp ./runs/train*/results.csv output_files/results_metrics.csv &&
      cp ./runs/train*/results.png output_files/results_plot.png 
    ]]>
    </command>
    <inputs>
        <param name="input_images" type="data" format="jpg,png,tiff" multiple="true"  label="Input images"/>
	    <param name="input_yolo" type="data" format="txt" multiple="true"  label="Input YOLO txt files" help="The YOLO text files, each text file must correspond to one input image (same name, different extension)." />
        <conditional name="model_choice">
            <param name="pretrained" type="select" label="Choose pretrained YOLO model or your own">
                <option value="personal">Your model from history</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt">YOLO11n-seg</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt">YOLO11n</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt">YOLOv8</option>
            </param>
            <when value="personal">
                <param name="model_input" type="data" format="data" label="Select your pretrained YOLO model from history" />
            </when>
            <when value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt"/>
            <when value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt"/>
            <when value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt"/>
        </conditional>
        <param name="class_names" type="text" optional="true" label="List class name comma separated"/>
		<section name="training_params" title="Training Parameters">
	        <param name="num_train" type="integer" value="70" min="50" max="90" label="How do you want to split your images for training?" help="Proportion of training images wrt valid and test images (in percents)." />
	        <param name="epochs" type="integer" value="100" min="10" max="1000" label="Number of epochs for taining." />
		    <param name="image_size" type="integer" value="640" min="16" max="1000" label="Image size" help="Target image size for training. All input images will be re-sized to squares with sides of this length (in pixels). This value governs the trade-offs of speed (smaller values) vs accuracy (larger values)." />
		    <param name="scale" type="float" value="0.5" min="0.1" max="0.9" label="Image scale augmentation" help="Image scale (+/- gain)." />
		    <param name="degree" type="float" value="0.0" min="0.0" max="20.0" label="Image rotation augmentation" help="Image rotation (+/- deg)." />
		    <param name="hsv_v" type="float" value="0.4" min="0.0" max="1.0" label="Image HSV-Value" help="Image HSV-Value augmentation (fraction)." />
		    <param name="hsv_s" type="float" value="0.7" min="0.0" max="1.0" label="Image HSV-Saturation" help="Image HSV-Saturation augmentation (fraction)." />
	        <param name="hsv_h" type="float" value="0.015" min="0.0" max="1.0" label="Image HSV-Hue" help="Image HSV-Hue augmentation (fraction)." />
		    <param name="init_lr" type="float" value="0.01" min="0.00001" max="0.1" label="Learning rate" help="Initial learning rate for training." />
	        <param name="weight_decay" type="float" value="0.0005" min="0.0001" max="0.1" label="Weight decay" />
	 	    <param name="confidence" type="float" value="0.5" min="0.0" max="1.0" label="Confidence" help="Confidence value (0-1) for each detected bounding box." />
		    <param name="iou" type="float" value="0.7" label="IoU" min="0.1" max="1.0" help="Intersection over Union threshold for non-maximum suppression." />
		    <param name="max_det" type="integer" value="300" min="100" max="1000" label="Max. number of detections" help="Maximum number of detections allowed per image. Limits the total number of objects the model can detect in a single inference, preventing excessive outputs in dense scenes." />
	    </section>
    </inputs>
    <outputs>
        <data name="best_model" auto_format="true" from_work_dir="output_files/best.pt" label="Best model"/>
        <data name="last_model" auto_format="true" from_work_dir="output_files/last.pt" label="Last Model"/>
        <data name="metrics_csv" format="csv" from_work_dir="output_files/results_metrics.csv" label="Training Metrics"/>
        <data name="metrics_plot" format="png" from_work_dir="output_files/results_plot.png" label="Training Plot"/>
    </outputs>
    <tests>
        <test>
	        <param name="input_images" location="https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0001.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0005.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0010.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0016.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0022.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0028.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0034.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0040.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0046.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0052.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0078.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0154.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0001.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0003.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0005.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0006.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0011.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0022.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0025.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0027.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0030.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0033.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0037.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0039.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0047.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0050.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0054.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0058.jpg" />
            <param name="input_yolo" location="https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0001.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0005.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0010.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0016.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0022.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0028.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0034.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0040.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0046.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0052.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0078.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0154.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0001.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0003.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0005.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0006.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0011.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0022.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0025.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0027.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0030.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0033.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0037.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0039.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0047.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0050.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0054.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0058.txt" />
            <conditional name="model_choice">
                <param name="pretrained" value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt"/>
            </conditional>            
            <section name="training_params">
				<param name="num_train" value="70" />
				<param name="epochs" value="10" />
				<param name="image_size" value="500" />
				<param name="scale" value="0.8" />
				<param name="degree" value="10.0" />
				<param name="hsv_v" value="0.5"/>
				<param name="init_lr" value="0.02" />
				<param name="weight_decay" value="0.001" />
            </section>
                <output name="best_model">
                    <assert_contents>
                        <has_size value="5960100" delta="100"/>
                    </assert_contents>
                </output>
                <output name="last_model">
                    <assert_contents>
                        <has_size value="5960100" delta="100"/>
                    </assert_contents>
                </output>
                <output name="metrics_csv">
                    <assert_contents>
                        <has_n_lines n="11"/>
                    </assert_contents>
	            </output>
	            <output name="metrics_plot" >
                    <assert_contents>
                        <has_size min="10000"/>
                        <has_image_channels channels="4"/>
                        <has_image_height height="1200"/>
						<has_image_width width="3600"/>						
                    </assert_contents>
                </output>
        </test>
        <test>
            <param name="input_images" value="0001.jpg,0003.jpg,0006.jpg,0007.jpg,0013.jpg,0016.jpg,0018.jpg,0021.jpg"/>
            <param name="input_yolo" value="0001,0003,0006,0007,0013,0016,0018,0021" />
            <conditional name="model_choice">
                <param name="pretrained" value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt"/>
            </conditional>
            <section name="training_params">
				<param name="num_train" value="70" />
				<param name="epochs" value="10" />
				<param name="image_size" value="500" />
				<param name="scale" value="0.8" />
				<param name="degree" value="10.0" />
				<param name="hsv_v" value="0.5"/>
				<param name="init_lr" value="0.02" />
				<param name="weight_decay" value="0.001" />
            </section>
                <output name="best_model">
                    <assert_contents>
                        <has_size value="5960100" delta="100"/>
                    </assert_contents>
                </output>
                <output name="last_model">
                    <assert_contents>
                        <has_size value="5960100" delta="100"/>
                    </assert_contents>
                </output>
                <output name="metrics_csv">
                    <assert_contents>
                        <has_n_lines n="11"/>
                    </assert_contents>
	            </output>
	            <output name="metrics_plot" >
                    <assert_contents>
                        <has_size min="10000"/>
                        <has_image_channels channels="4"/>
                        <has_image_height height="1200"/>
						<has_image_width width="3600"/>	
                    </assert_contents>
                </output>
        </test>
        <test>
            <param name="input_images" value="YOLO_jpg/006.jpg,YOLO_jpg/007.jpg,YOLO_jpg/008.jpg,YOLO_jpg/009.jpg,YOLO_jpg/010.jpg"/> 
            <param name="input_yolo" value="YOLO_txt/006.txt,YOLO_txt/007.txt,YOLO_txt/008.txt,YOLO_txt/009.txt,YOLO_txt/010.txt" /> 
            <conditional name="model_choice">
                <param name="pretrained" value="personal"/>
                <param name="model_input" location="https://zenodo.org/records/17631929/files/custom_yolo_model.zip?download=1"/> <!-- Trained with YOLOv11-seg,on files 1 to 5, best model selected -->
            </conditional>
            <section name="training_params">
				<param name="num_train" value="70" />
				<param name="epochs" value="10" />
				<param name="image_size" value="640" />
				<param name="scale" value="0.5" />
				<param name="hsv_v" value="0.5"/>
				<param name="init_lr" value="0.02" />
				<param name="weight_decay" value="0.001" />
            </section>
                <output name="best_model">
                    <assert_contents>
                        <has_size value="5969892" delta="100"/>
                    </assert_contents>
                </output>
                <output name="last_model">
                    <assert_contents>
                        <has_size value="5969892" delta="100"/>
                    </assert_contents>
                </output>
                <output name="metrics_csv">
                    <assert_contents>
                        <has_n_lines n="11"/>
                    </assert_contents>
	            </output>
	            <output name="metrics_plot" >
                    <assert_contents>
                        <has_size min="10000"/>
                        <has_image_channels channels="4"/>
                        <has_image_height height="1200"/>
						<has_image_width width="3600"/>	
                    </assert_contents>
                </output>
        </test>
    </tests>
    <help><![CDATA[
        **What it does**
	    This tool processes a dataset of images by splitting them into training, validation, and test sets, then trains a machine learning model based on
	    YOLO models from the Ultralytics package.
        
	**Overview**
	    1. **Input images**: Provide a collection of images for training. Each image is a sample for detection/segmentation.

	    2. **Input YOLO txt files**: A collection of YOLO .txt annotation files. Each file must have the same name as its corresponding image 
	    (e.g. image1.jpg <-> image1.txt).

	    3. **Dataset splitting**: The images are automatically split into training, validation and test set.

        4. **Model training**: Parameters used to train a model using YOLO.

        **Outputs:**
            - `best.pt`: The best-performing model checkpoint based on validation metrics.
            - `last.pt`: The final model checkpoint from the end of training.
            - `results_metrics.csv`: A CSV file containing performance metrics.
            - `results_plot.png`: A visual plot summarizing the model performance.
    ]]>
    </help>
    <expand macro="citations" />
</tool>
