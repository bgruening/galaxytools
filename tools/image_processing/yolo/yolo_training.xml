<tool id="yolo_training" name="Perform YOLO training" version="@TOOL_VERSION@+galaxy@VERSION_SUFFIX@" profile="24.2">
    <description>with ultralytics</description>
    <macros>
        <import>macros.xml</import>
    </macros>
    <expand macro="creator" />
    <expand macro="edam" />
    <expand macro="requirements" />
    <command detect_errors="aggressive">
    <![CDATA[
      export YOLO_CONFIG_DIR='\$HOME/.config/ultralytics' &&

      mkdir -p ./input_images ./input_yolo ./training ./runs ./models output_files && 

      #for $filename in $input_images:
          ln -s '$filename' './input_images/${filename.element_identifier}' &&
      #end for
	
      #for $yolo in $input_yolo:
          ln -s '$yolo' './input_yolo/${yolo.element_identifier}' &&
      #end for

      python '$__tool_directory__/preprocessing.py' -i './input_images' -y './input_yolo' -o ./training -p '$num_train' &&

      wget '$training_params.model_url' -O ./models/yolo_model.pt &&
		    
      
      python '$__tool_directory__/yolov8.py' 
		    --train --yaml_path='./training/yolo.yml' 
		    --model_path='./models' 
     		    --model_name='yolo_model'
		    --run_dir='./runs' 
		    --image_size='$training_params.image_size'
		    --epochs='$training_params.epochs'
		    --scale='$training_params.scale'
		    --degree='$training_params.degree'
		    --hsv_v='$training_params.hsv_v'
		    --hsv_s='$training_params.hsv_s'
		    --hsv_h='$training_params.hsv_h'
		    --init_lr='$training_params.init_lr'
		    --weight_decay='$training_params.weight_decay'
		    --confidence='$training_params.confidence'
		    --iou='$training_params.iou'
		    --max_det='$training_params.max_det'  

      &&

      cp ./runs/train*/*/best.pt output_files/best.pt &&
      cp ./runs/train*/*/last.pt output_files/last.pt &&
      cp ./runs/train*/results.csv output_files/results_metrics.csv &&
      cp ./runs/train*/results.png output_files/results_plot.png 
    ]]>
    </command>
    <inputs>
        <param name="input_images" type="data" format="jpg" multiple="true"  label="Input images"/>
        <param name="input_yolo" type="data" format="txt" multiple="true"  label="Input YOLO txt files" help="The YOLO text files, each text file must correspond to one input image (same name different extension)." />
	<section name="training_params" title="Training Parameters">
            <param name="num_train" type="integer" value="70" min="50" max="90" label="How do you want to split your images for training?" help="Proportion of training images wrt valid and test images (in percents)." />
	    <param name="model_url" type="text">
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt">YOLO11n-seg</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt">YOLO11n</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt">YOLOv8</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/sam_b.pt">SAM base</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/sam_l.pt">SAM large</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/sam2_t.pt">SAM2 tiny</option>
                <option value="https://github.com/ultralytics/assets/releases/download/v8.3.0/sam2.1_t.pt">SAM2.1 tiny</option>
            </param>
            <param name="epochs" type="integer" value="100" min="10" max="1000" label="Number of epochs for taining." />
	    <param name="image_size" type="integer" value="1000" min="16" max="1000" label="Image size" help="Target image size for training. All input images will be re-sized to squares with sides of this length (in pixels). This value governs the trade-offs of speed (smaller values) vs accuracy (larger values)." />
	    <param name="scale" type="float" value="0.5" min="0.1" max="0.9" label="Image scale augmentation" help="Image scale (+/- gain)." />
	    <param name="degree" type="float" value="0.0" min="0.0" max="20.0" label="Image rotation augmentation" help="Image rotation (+/- deg)." />
	    <param name="hsv_v" type="float" value="0.4" min="0.0" max="1.0" label="Image HSV-Value" help="Image HSV-Value augmentation (fraction)." />
	    <param name="hsv_s" type="float" value="0.7" min="0.0" max="1.0" label="Image HSV-Saturation" help="Image HSV-Saturation augmentation (fraction)." />
            <param name="hsv_h" type="float" value="0.015" min="0.0" max="1.0" label="Image HSV-Hue" help="Image HSV-Hue augmentation (fraction)." />
	    <param name="init_lr" type="float" value="0.01" min="0.00001" max="0.1" label="Learning rate" help="Initial learning rate for training." />
            <param name="weight_decay" type="float" value="0.0005" min="0.0001" max="0.1" label="Weight decay" />
 	    <param name="confidence" type="float" value="0.5" min="0.0" max="1.0" label="Confidence" help="Confidence value (0-1) for each detected bounding box." />
	    <param name="iou" type="float" value="0.7" label="IoU" min="0.1" max="1.0" help="Intersection over Union threshold for non-maximum suppression." />
	    <param name="max_det" type="integer" value="300" min="100" max="1000" label="Max. number of detections" help="Maximum number of detections allowed per image. Limits the total number of objects the model can detect in a single inference, preventing excessive outputs in dense scenes." />
        </section>
    </inputs>
    <outputs>
        <data name="best_model" auto_format="true" from_work_dir="output_files/best.pt" label="Best Model"/>
        <data name="last_model" auto_format="true" from_work_dir="output_files/last.pt" label="Last Model"/>
        <data name="metrics_csv" format="csv" from_work_dir="output_files/results_metrics.csv" label="Training Metrics"/>
        <data name="metrics_plot" format="png" from_work_dir="output_files/results_plot.png" label="Training Plot"/>
    </outputs>
    <tests>
        <test>
	    <param name="input_images" location="https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0001.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0005.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0010.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0016.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0022.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0028.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0034.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0040.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0046.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0052.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0078.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0154.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0001.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0003.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0005.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0006.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0011.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0022.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0025.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0027.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0030.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0033.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0037.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0039.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0047.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0050.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0054.jpg,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0058.jpg" />
            <param name="input_yolo" location="https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0001.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0005.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0010.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0016.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0022.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0028.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0034.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0040.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0046.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0052.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0078.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0001_P0001-0154.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0001.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0003.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0005.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0006.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0011.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0022.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0025.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0027.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0030.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0033.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0037.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0039.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0047.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0050.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0054.txt,https://zenodo.org/records/15611612/files/C2-MAX_20230223_DE_W0002_P0001-0058.txt" />
	    <section name="training_params">
                <param name="num_train" value="70" />
		<param name="model_url" value="https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt" />
                <param name="epochs" value="10" />
                <param name="image_size" value="500" />
                <param name="scale" value="0.8" />
                <param name="degree" value="10.0" />
                <param name="hsv_v" value="0.5"/>
                <param name="init_lr" value="0.02" />
                <param name="weight_decay" value="0.001" />
	    </section>
             <output name="best_model">
                <assert_contents>
                    <has_size value="5960100" delta="100"/>
                </assert_contents>
            </output>
            <output name="last_model">
                <assert_contents>
                    <has_size value="5960100" delta="100"/>
                </assert_contents>
            </output>
            <output name="metrics_csv">
                <assert_contents>
                    <has_n_lines n="11"/>
                </assert_contents>
	    </output>
	    <output name="metrics_plot" file="results_plot.png" compare="image_diff" />
        </test>
    </tests>
    <help><![CDATA[
        **What it does**
	    This tool processes a dataset of images by splitting them into training, validation, and test sets, then trains a machine learning model based on
	    YOLO models from the Ultralytics package.
        
	**Overview**
	    1. **Input images**: Provide a collection of images for training. Each image is a sample for detection/segmentation.

	    2. **Input YOLO txt files**: A collection of YOLO .txt annotation files. Each file must have the same name as its corresponding image 
	    (e.g. image1.jpg <-> image1.txt).

	    3. **Dataset splitting**: The images are automatically split into training, validation and test set.

            4. **Model training**: Parameters used to train a model using YOLO.

        **Outputs:**
            - `best.pt`: The best-performing model checkpoint based on validation metrics.
            - `last.pt`: The final model checkpoint from the end of training.
            - `results_metrics.csv`: A CSV file containing performance metrics.
            - `results_plot.png`: A visual plot summarizing the model performance.
    ]]>
    </help>
    <expand macro="citations" />
</tool>
