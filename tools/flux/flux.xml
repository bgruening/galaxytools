<tool id="black-forest-labs-flux" name="FLUX" version="@TOOL_VERSION@+galaxy@VERSION_SUFFIX@" profile="23.0">
    <description>Integrating FLUX (text-to-image and image-to-image) model into Galaxy</description>
    <macros>
        <token name="@TOOL_VERSION@">2024</token>
        <token name="@VERSION_SUFFIX@">0</token>
    </macros>
    <requirements>
        <requirement type="package" version="3.12">python</requirement>
        <requirement type="package" version="2.4.1">pytorch</requirement>
        <requirement type="package" version="0.30.2">diffusers</requirement>
    </requirements>
    <!-- here should be passed the flux_models_path(folder_base_path) and model(id) -->
    <command detect_errors="exit_code"><![CDATA[
export HF_HOME='$flux_models.index.fields.path'
python '$__tool_directory__/flux.py'
'$flux_models.index'
'$prompt'
'$huggingface_hub_token_path'
    ]]></command>
    <configfiles>
        <configfile name="huggingface_hub_token_path"><![CDATA[
$__user__.extra_preferences.get('flux|huggingface_hub_token', "")
        ]]></configfile>
    </configfiles>
    <inputs>
        <param name="flux_models" label="Model data" type="select" help="contact the administrator of this Galaxy instance if you miss model data">
            <options from_data_table="huggingface">
              <filter type="static_value" value="flux" column="2"/>
            </options>
            <validator message="No model annotation is available for FLUX" type="no_options" />
        </param>
        <param name="prompt" type="text" optional="false" label="Prompt" help="This text will be used as prompt" area="true">
            <validator type="empty_field"/>
        </param>
        <!-- <conditional name="input_type">
            <param name="input_type_selector" type="select" label="Choose the type of input">
                <option value="file" selected="true">File based input</option>
                <option value="text">Text based input</option>
            </param>
            <when value="file">
                <param name="prompt" type="data" optional="false" format="doc,docx,html,json,pdf,txt,jpg,jpeg,png,webp,gif" label="Prompt file" help="This data will be used as prompt"/>
            </when>
            <when value="text">
                <param name="prompt" type="text" optional="false" label="Prompt" help="This text will be used as prompt" area="true">
                    <validator type="empty_field"/>
                </param>
            </when>
        </conditional> -->
    </inputs>
    <outputs>
        <data name="output" format="png" label="${tool.name} on ${on_string}" from_work_dir="./output.png"/>
    </outputs>
    <!-- <tests>
        <test expect_failure="true" expect_exit_code="1">
            <param name="context" value="flux_test.txt" ftype="txt"/>
            <param name="model" value="schnell"/>
            <assert_stdout>
                <has_text text="OpenAI API key is not provided in user preferences!"/>
            </assert_stdout>
        </test>
    </tests> -->
    <help><![CDATA[

.. class:: infomark

**What it does**

Usage
.....

**Input**


**Output**


    ]]></help>
    <citations>
        <citation type="bibtex">
            @misc{flux,
                author = {black forest labs},
                title = {FLUX github repository},
                howpublished = {\url{https://github.com/black-forest-labs/flux}},
                year = {2024},
                note = {Accessed: 2024-09-04}
            }
        </citation>
    </citations>
</tool>
